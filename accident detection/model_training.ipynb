{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7937d55e-20ac-4d1e-803b-a8d353148112",
   "metadata": {},
   "source": [
    "# System Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa77f2f-b889-48e5-ad9d-ae4a611b8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb9793-b4c7-4a22-89d4-b67e58a2ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU Details:\", gpus)\n",
    "    print(\"TensorFlow is using the GPU\")\n",
    "else:\n",
    "    print(\"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8356fc-1268-428c-897c-16da6fe17a80",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f0a96-3356-4d90-979a-434e6e16b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b93cfa-463a-40f5-b8a3-7609f30b3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations use paraller processing,,,\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=3, p=0.2),\n",
    "], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a815c-df73-4c84-b710-34dd8c23cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_labels(label_path):\n",
    "    if not os.path.exists(label_path):\n",
    "        return []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        return [list(map(float, line.strip().split())) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7524c-b340-49d8-9959-0ae9b59907bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_yolo_labels(label_path, labels):\n",
    "    with open(label_path, \"w\") as f:\n",
    "        for label in labels:\n",
    "            f.write(\" \".join(map(str, label)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86597ea6-35e6-4819-9257-04fe951a4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image_path, label_path, output_dir):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e7784-39d9-4b8f-99ea-7dda796257bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image_path, label_path, output_dir):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    labels = load_yolo_labels(label_path)\n",
    "    \n",
    "    if not labels:\n",
    "        return\n",
    "\n",
    "    bboxes = [[x, y, bw, bh] for _, x, y, bw, bh in labels]\n",
    "    class_labels = [label[0] for label in labels]\n",
    "\n",
    "    for i in range(3):  # 3 augmentations per image\n",
    "        augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        aug_img = augmented[\"image\"]\n",
    "        aug_bboxes = augmented[\"bboxes\"]\n",
    "\n",
    "        new_labels = [[cls] + list(bbox) for bbox, cls in zip(aug_bboxes, class_labels)]\n",
    "\n",
    "        output_image_path = os.path.join(output_dir, \"images\", f\"aug_{i}_{os.path.basename(image_path)}\")\n",
    "        output_label_path = os.path.join(output_dir, \"labels\", f\"aug_{i}_{os.path.basename(label_path)}\")\n",
    "        \n",
    "        cv2.imwrite(output_image_path, aug_img)\n",
    "        save_yolo_labels(output_label_path, new_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0007c62-d42a-4307-a773-bac679077866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_file):\n",
    "    image_path = os.path.join(r\"F:\\camera\\accident detection\\dataset\\train\\images\", image_file)\n",
    "    label_path = os.path.join(r\"F:\\camera\\accident detection\\dataset\\train\\labels\", image_file.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\"))\n",
    "    augment_image(image_path, label_path, r\"F:\\camera\\accident detection\\delete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6d6a5-76cb-434b-af0b-5a758c8fc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(r\"F:\\camera\\accident detection\\delete\\images\", exist_ok=True)\n",
    "    os.makedirs(r\"F:\\camera\\accident detection\\delete\\labels\", exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(r\"F:\\camera\\accident detection\\dataset\\train\\images\") if f.endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(process_image, image_files), total=len(image_files)))\n",
    "\n",
    "    print(\"Fast Albumentations augmentation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c89a22-81b4-4c06-b631-603176dbc0bd",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6886a4d-cf0a-46e8-b316-ab078c8c15a5",
   "metadata": {},
   "source": [
    "# Phase I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7674c-600b-49a0-9098-f2ed0cc68a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f990346-fd30-496d-8a03-74151a717709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4710ef-685b-4b51-bc2f-eda42ddb4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = r'F:\\camera\\accident detection\\dataset\\data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8ca31-480c-405e-93a4-64ef32649983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data=data_yaml, epochs=10, batch=16, augment=False, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350608af-e9f5-44ad-a2a4-29ef2e79880c",
   "metadata": {},
   "source": [
    "# Phase II (*10 - 20 Epochs*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24694ac8-a494-474f-b5ff-ba9342743399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63541d12-222c-4a20-b53b-def89469e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r\"F:\\camera\\accident detection\\runs\\detect\\train30\\weights\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61c8f4-33f0-4204-a394-16e46e2419a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(data=data_yaml, epochs=10, batch=16, augment=False, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9c082-e3e2-4ea2-b305-caf29ac377e6",
   "metadata": {},
   "source": [
    "# Phase III (*20 - 30 Epochs*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1e9cb-eee0-4baa-b75c-73e5285d23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd00e8e-f5c7-4dbd-9c14-04b794297396",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r\"F:\\camera\\accident detection\\runs\\detect\\train30\\weights\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e57cbb-c9ab-42e6-9ad5-e29b349d2200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(data=data_yaml, epochs=10, batch=16, augment=False, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882f9e1-1617-4741-b280-7856ec80269f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c3f15a-a3ec-4e2f-8e9e-a65e37a2a444",
   "metadata": {},
   "source": [
    "# Phase IV (*30 - 40 Epochs*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2acbd8-7aaa-42e9-a4d6-f6e064c6e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86737de-1ff4-496d-9877-4d2f04eeb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r\"F:\\camera\\accident detection\\runs\\detect\\train30\\weights\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41895d0-8247-4519-8ca5-8db72e760a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data=data_yaml, epochs=10, batch=16, augment=False, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea8bc9-94eb-4f3d-9f74-248de268f1e0",
   "metadata": {},
   "source": [
    "# Phase V (*40 - 50 Epochs*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3f5ab-883b-41d5-a278-6258ad14a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392f62b-8d65-4691-bc82-c66edda976e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r\"F:\\camera\\accident detection\\runs\\detect\\train30\\weights\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18da70-7d68-47b4-8a95-7f41a4e05f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data=data_yaml, epochs=10, batch=16, augment=False, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aebb89-4db6-494c-8ab5-07841bb1c1a8",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4858b-5554-4026-883f-d1e71be2b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(r\"F:\\camera\\accident detection\\runs\\detect\\train30\\weights\\best.pt\")\n",
    "\n",
    "class_names = {\n",
    "    0: \"Accident\",\n",
    "    1: \"NoAccident\",\n",
    "    2: \"Car\",\n",
    "    3: \"Mild\",\n",
    "    4: \"Moderate\",\n",
    "    5: \"Motor Cycle\",\n",
    "    6: \"Severe\"\n",
    "}\n",
    "\n",
    "video_path = \"demo_accident.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "display_width = 800  # Adjust as needed\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "    new_height = int(display_width / aspect_ratio)\n",
    "    frame = cv2.resize(frame, (display_width, new_height))\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box\n",
    "            conf = float(box.conf[0])  # Confidence score\n",
    "            cls = int(box.cls[0])  # Class ID\n",
    "            label = f\"{class_names.get(cls, 'Unknown')} ({conf:.2f})\"\n",
    "\n",
    "            color = (0, 0, 255) if cls == 0 else (0, 255, 0) if cls == 1 else (255, 0, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    cv2.imshow(\"Accident Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a9a58-d99a-4675-a616-9fa0134bc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "video_path = \"demo_accident.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851be8d-190c-4ec3-864a-dccbc445e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".camera_venv",
   "language": "python",
   "name": ".camera_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
